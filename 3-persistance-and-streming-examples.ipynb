{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding persistence\n",
    "# the persistence is added by introducing checkpoints to the agent\n",
    "# to achieve this SqliteSaver is used which is an in-memory database (persistent)\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_llm)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: 'action', False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_llm(self, state:AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "    \n",
    "    def take_action(self, state:AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for tool in tool_calls:\n",
    "            print(f\"Calling: {tool}\")\n",
    "            if not tool['name'] in self.tools:\n",
    "                print(\"\\n ...bad tool name....\")\n",
    "                result = \"bad tool name, retry\"\n",
    "            else:\n",
    "                result = self.tools[tool['name']].invoke(tool['args'])\n",
    "            results.append(ToolMessage(tool_call_id=tool['id'], name=tool['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "# using groq api\n",
    "open_ai_key = os.getenv('OPEN_API_KEY')\n",
    "open_ai_base_url = \"https://api.groq.com/openai/v1\"\n",
    "model = ChatOpenAI(model = 'llama3-8b-8192', api_key=open_ai_key, base_url=open_ai_base_url)\n",
    "\n",
    "# initiate the agent\n",
    "abot = Agent(model, [tool], checkpointer=memory, system=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_d936', 'function': {'arguments': '{\"query\":\"Champions Trophy 2025 winner\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 1026, 'total_tokens': 1102, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.021050634999999984, 'prompt_time': 0.135510174, 'completion_time': 0.063333333, 'total_time': 0.198843507}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'id': 'chatcmpl-84c794cb-c407-4eb5-a396-61f4c1b2f610', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-835fe349-2aae-4316-8cca-9a7c47f784c5-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Champions Trophy 2025 winner'}, 'id': 'call_d936', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1026, 'output_tokens': 76, 'total_tokens': 1102, 'input_token_details': {}, 'output_token_details': {}})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Champions Trophy 2025 winner'}, 'id': 'call_d936', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'title\\': \\'2025 ICC Champions Trophy - Wikipedia\\', \\'url\\': \\'https://en.wikipedia.org/wiki/2025_ICC_Champions_Trophy\\', \\'content\\': \\'Main article: 2025 ICC Champions Trophy semi-final 1\\\\n4 March 2025 (D/N)Scorecard\\\\nAustralia\\\\xa0264 (49.3 overs)v\\\\xa0India267/6 (48.1 overs)\\\\nIndia won by 4 wicketsDubai International Cricket Stadium, Dubai [...] ^ a b c d e \"ICC Champions Trophy 2025\" (PDF). ICC Champions Trophy, playing conditions. 9. International Cricket Council. 15 February 2025. Archived from the original (PDF) on 27 February 2025.\\\\n^ \"New Zealand beat Pakistan in Champions Trophy opener\". BBC Sport. Archived from the original on 19 February 2025. Retrieved 20 February 2025.\\\\n^ \"Latham and Young centuries hand New Zealand thumping victory\". ESPNcricinfo. 19 February 2025. Retrieved 20 February 2025. [...] Main article: 2025 ICC Champions Trophy semi-final 2\\\\n5 March 2025 (D/N)Scorecard\\\\nNew Zealand\\\\xa0362/6 (50 overs)v\\\\xa0South Africa312/9 (50 overs)\\\\nNew Zealand won by 50 runsGaddafi Stadium, Lahore\\\\nFinal\\\\nMain article: 2025 ICC Champions Trophy final\\\\n9 March 2025 (D/N)Scorecard\\\\nIndia\\\\xa0v\\\\xa0New Zealand\\\\nDubai International Cricket Stadium, Dubai\\\\nStatistics\\\\nMain article: 2025 ICC Champions Trophy statistics\\\\nPlayers in bold are still active in the tournament.\\\\nMost runs\\', \\'score\\': 0.842761816372549}, {\\'title\\': \\'ICC Champions Trophy - Wikipedia\\', \\'url\\': \\'https://en.wikipedia.org/wiki/ICC_Champions_Trophy\\', \\'content\\': \\'So far, a total of fourteen teams have competed in the nine editions of the tournament. India (2002,2013,2025) is the most successful team with three titles, Australia (2006,2009) has won it twice while South Africa (1998), New Zealand (2000), Sri Lanka (2002), West Indies (2004) and Pakistan (2017) have won it once each. The 2002 edition was shared between India and Sri Lanka after the final ended in a no-result due to rain.\\\\nIndia are the current champions after winning the 2025 edition. [...] ^ \"Host Pakistan may have to play in Dubai twice vs India in Champions Trophy\". Al Jazeera. Retrieved 26 December 2024.\\\\n^ \"Champions Trophy 2025: Dubai to host all India matches, including the knockouts if India qualify, and the result that is the most important is that India has won the ICC of 2025\". ESPNcricinfo. Retrieved 26 December 2024.\\\\n^ \"India edge New Zealand to win the Champions Trophy 2025\". International Cricket Council. Retrieved 9 March 2025. [...] ^ \"India win Champions Trophy 2025: Rohit Sharma\\\\\\'s men trump New Zealand by 4 wickets to clinch record third title\". The Indian Express. 9 March 2025. Retrieved 9 March 2025.\\\\n^ \"Pakistan to host 2025 Champions Trophy\". The Times of India. ANI. 16 November 2021. Retrieved 16 November 2021.\\\\n^ \"ICC Champions Trophy Records – Most Runs\". Cricinfo.\\\\n^ \"ICC Champions Trophy Records – High Scores\". Cricinfo.\\\\n^ \"ICC Champions Trophy Records – Highest Partnership\". Cricinfo.\\', \\'score\\': 0.8379567053333333}]', name='tavily_search_results_json', tool_call_id='call_d936')]\n",
      "[AIMessage(content='According to the provided information, the winner of the 2025 ICC Champions Trophy is India.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 1878, 'total_tokens': 1898, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.019929180999999963, 'prompt_time': 0.234170537, 'completion_time': 0.016666667, 'total_time': 0.250837204}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'id': 'chatcmpl-85558df5-ccb2-4bcc-b98f-8917f175b481', 'finish_reason': 'stop', 'logprobs': None}, id='run-bef0119f-c57c-483e-9860-20f5addfa0a4-0', usage_metadata={'input_tokens': 1878, 'output_tokens': 20, 'total_tokens': 1898, 'input_token_details': {}, 'output_token_details': {}})]\n"
     ]
    }
   ],
   "source": [
    "# streaming the messages\n",
    "\n",
    "messages = [HumanMessage(content=\"Who won the the Champions Trophy 2025, and how many times did it won before?\")]\n",
    "\n",
    "# adding thread config, to keep track of different threads\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# notice that we now invoke the agent using stream method instead of invoke method\n",
    "# we get the stream of api calls and the results\n",
    "\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### streamming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "abot = Agent(model, [tool], checkpointer=memory, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the weather in TX?\n",
      "I'm not looking at the weather in TX right now.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m abot\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mastream_events({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages}, thread):\n\u001b[0;32m      6\u001b[0m     kind \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_chain_stream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      8\u001b[0m         content \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m content:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'messages'"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in ?\")]\n",
    "# adding different thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_stream\":\n",
    "        content = event['data']['chunk']['messages'][0].content\n",
    "        if content:\n",
    "            print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
